{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eed6331f-f905-4732-a258-41499566f231",
   "metadata": {
    "tags": []
   },
   "source": [
    "# How many edits would Automoderator revert per day at different caution levels?\n",
    "\n",
    "[TASK: T348869](https://phabricator.wikimedia.org/T348869)\n",
    "\n",
    "**Purpose**<br>As part of the model testing process, we want to understand how many can we expect Automoderator revert per day on average. \n",
    "This will be helpful for community to understand the potential impact of Automoderator. For the analysis, [revert risk scores generated by WMF's Research team](https://gitlab.wikimedia.org/repos/research/knowledge_integrity/-/blob/mnz/examples/examples/notebooks/revertrisk_example.ipynb) were used, and edits made by admins, bots, self-reverts, and new page creations were excluded.\n",
    "\n",
    "**Results**<br>Average daily number of edits Automoderator would potentially revert per day at different thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62bbd38-fcf6-4072-ab6a-6f9f6a319c31",
   "metadata": {},
   "source": [
    "# Data-Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b058a4d4-3f04-47bf-8e27-67177ee63cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wmfdata as wmf\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1bfa4a-1dfa-4e7d-8aa6-b5faaf5b91e7",
   "metadata": {},
   "source": [
    "## spark_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f62e84d-751a-4a5f-aad0-5769e59a1370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no active session\n"
     ]
    }
   ],
   "source": [
    "spark_session = wmf.spark.get_active_session()\n",
    "\n",
    "if type(spark_session) != type(None):\n",
    "    spark_session.stop()\n",
    "else:\n",
    "    print('no active session')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "566a462d-5ceb-468a-bae9-c3ddc0a77e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://stat1005.eqiad.wmnet:4048\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>automod-activity</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f474961e3e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_session = wmf.spark.create_custom_session(\n",
    "    master=\"yarn\",\n",
    "    app_name='automod-activity',\n",
    "    spark_config={\n",
    "        \"spark.driver.memory\": \"4g\",\n",
    "        \"spark.dynamicAllocation.maxExecutors\": 64,\n",
    "        \"spark.executor.memory\": \"16g\",\n",
    "        \"spark.executor.cores\": 4,\n",
    "        \"spark.sql.shuffle.partitions\": 256,\n",
    "        \"spark.driver.maxResultSize\": \"2g\"\n",
    "        \n",
    "    }\n",
    ")\n",
    "\n",
    "clear_output()\n",
    "\n",
    "spark_session.sparkContext.setLogLevel(\"ERROR\")\n",
    "spark_session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed353e4c-580e-478f-99b2-7cc87c41697d",
   "metadata": {},
   "source": [
    "## query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37c5ea7f-7008-42df-b8f0-56d7ba3afef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- rev_id: long (nullable = true)\n",
      " |-- wiki_db: string (nullable = true)\n",
      " |-- rev_timestamp: string (nullable = true)\n",
      " |-- revision_is_identity_reverted: boolean (nullable = true)\n",
      " |-- revision_seconds_to_identity_revert: long (nullable = true)\n",
      " |-- page_id: long (nullable = true)\n",
      " |-- revision_revert_risk: float (nullable = true)\n",
      " |-- user_is_anonymous: boolean (nullable = true)\n",
      " |-- user_is_bot: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# paths to pre-calculated revert risk scores\n",
    "# generated by https://gitlab.wikimedia.org/repos/research/knowledge_integrity/-/blob/mnz/examples/examples/notebooks/revertrisk_example.ipynb\n",
    "rr_scores_path = '/user/paragon/riskobservatory/revertrisk_20212022_anonymous_bot.parquet'\n",
    "\n",
    "rr_scores = spark_session.read.parquet(rr_scores_path)\n",
    "rr_scores.createOrReplaceTempView('rr_scores')\n",
    "\n",
    "rr_scores.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb27fe01-cbe6-4674-bd88-82b5ed54866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# risk thresholds: in steps of 0.005 until 0.95 and in steps of 0.01 from 0.95 to 0.9\n",
    "risk_thresholds = [0.99 - i*0.005 for i in range(9)] + [round(0.94 - i*0.01, 2) for i in range(5)]\n",
    "\n",
    "# generate CASE WHEN statements based on the risk thresholds\n",
    "risk_case_statements = [\n",
    "    f\"SUM(CASE WHEN risk > {threshold} THEN 1 ELSE 0 END) AS t_{str(threshold).replace('.', '_')}\"\n",
    "    for threshold in risk_thresholds\n",
    "]\n",
    "risk_case_sql = ',\\n        '.join(risk_case_statements)\n",
    "\n",
    "# average select statements based on the risk thresholds\n",
    "avg_select_statements = [\n",
    "    f\"CAST(ROUND(AVG(t_{str(threshold).replace('.', '_')})) AS INT) AS t_{str(threshold).split('.')[1]}\"\n",
    "    for threshold in risk_thresholds\n",
    "]\n",
    "avg_select_sql = ',\\n    '.join(avg_select_statements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1863e2f5-7138-455a-b0d2-2a0b1767d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_comparision = pd.read_csv('https://raw.githubusercontent.com/wikimedia-research/wiki-comparison/main/data-collection/snapshots/Jan_2023.tsv', sep='\\t')\n",
    "top150_wps = (\n",
    "    wiki_comparision[wiki_comparision['project code'] == 'wikipedia']\n",
    "    .reset_index(drop=True)\n",
    "    .iloc[:150, :]['database code']\n",
    "    .values.tolist()\n",
    ")\n",
    "\n",
    "wikis_sql = wmf.utils.sql_tuple(top150_wps)\n",
    "mwh_snapshot = '2023-10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f69be72-ed13-4923-a0d6-2fcf8f277697",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/13 07:54:36 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 390 ms, sys: 110 ms, total: 501 ms\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "query = f\"\"\"\n",
    "WITH base AS (\n",
    "    SELECT\n",
    "        rr.wiki_db,\n",
    "        rr.rev_id,\n",
    "        revision_revert_risk AS risk,\n",
    "        event_user_text,\n",
    "        DATE(event_timestamp) AS date,\n",
    "        mwh.revision_is_identity_revert,\n",
    "        CASE \n",
    "            WHEN mwh.revision_is_identity_revert THEN 'revert' \n",
    "            ELSE 'non_revert' \n",
    "        END AS revision_type\n",
    "    FROM \n",
    "        rr_scores rr\n",
    "    JOIN \n",
    "        wmf.mediawiki_history mwh \n",
    "        ON rr.wiki_db = mwh.wiki_db AND rr.rev_id = mwh.revision_id\n",
    "    WHERE \n",
    "        snapshot = '{mwh_snapshot}'\n",
    "        AND rr.wiki_db IN {wikis_sql}\n",
    "        -- exclude page creations\n",
    "        AND mwh.revision_parent_id <> 0\n",
    "        -- exclude adminstrators\n",
    "        AND NOT ARRAY_CONTAINS(mwh.event_user_groups, 'sysop')\n",
    "        -- exclude bots\n",
    "        AND SIZE(event_user_is_bot_by) = 0\n",
    "        AND YEAR(event_timestamp) = 2022\n",
    "),\n",
    "\n",
    "excl_self_reverts AS (\n",
    "    SELECT\n",
    "        b.*\n",
    "    FROM\n",
    "        base b\n",
    "    JOIN wmf.mediawiki_history mwh\n",
    "        ON b.rev_id = mwh.revision_first_identity_reverting_revision_id\n",
    "    WHERE\n",
    "        snapshot = '{mwh_snapshot}'\n",
    "        AND b.revision_type = 'revert'\n",
    "        -- exclude self reverts\n",
    "        AND b.event_user_text <> mwh.event_user_text\n",
    "),\n",
    "\n",
    "sample AS (\n",
    "    SELECT * FROM base WHERE revision_type = 'non_revert'\n",
    "    UNION ALL\n",
    "    SELECT * FROM excl_self_reverts\n",
    "),\n",
    "\n",
    "count_score AS (\n",
    "    SELECT\n",
    "        date,\n",
    "        wiki_db,\n",
    "        {risk_case_sql}\n",
    "    FROM\n",
    "        base\n",
    "    GROUP BY\n",
    "        wiki_db,\n",
    "        date\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    wiki_db,\n",
    "    {avg_select_sql}\n",
    "FROM\n",
    "    count_score\n",
    "GROUP BY\n",
    "    wiki_db\n",
    "ORDER BY\n",
    "    wiki_db\n",
    "\"\"\"\n",
    "\n",
    "result = wmf.spark.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e47475e5-660c-4fe5-927c-fe293bae3cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values('t_99', ascending=False).to_csv('revert_risk_reverts.tsv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
