{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "125890df-0b34-4890-8f81-2e93b27af763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wmfdata as wmf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import FuncFormatter, FixedLocator\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "from IPython.display import display_html, display, HTML, clear_output\n",
    "import warnings\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b99426-147d-49e0-aec8-82dfc533db6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://stat1005.eqiad.wmnet:4048\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>automod-reviews-per-day</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f956706aad0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_session = wmf.spark.get_active_session()\n",
    "\n",
    "if type(spark_session) == type(None):\n",
    "    spark_session = wmf.spark.create_custom_session(\n",
    "        master=\"yarn\",\n",
    "        app_name='automod-reviews-per-day',\n",
    "        spark_config={\n",
    "            \"spark.driver.memory\": \"4g\",\n",
    "            \"spark.dynamicAllocation.maxExecutors\": 64,\n",
    "            \"spark.executor.memory\": \"16g\",\n",
    "            \"spark.executor.cores\": 4,\n",
    "            \"spark.sql.shuffle.partitions\": 256,\n",
    "            \"spark.driver.maxResultSize\": \"2g\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "spark_session.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "clear_output()\n",
    "\n",
    "spark_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "39b101c0-27a5-4d8d-bef8-87e68a5af015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints a string at center of the output, bold if needed\n",
    "def pr_centered(content, bold=False):\n",
    "    if bold:\n",
    "        content = f\"<b>{content}</b>\"\n",
    "    \n",
    "    centered_html = f\"<div style='text-align:center'>{content}</div>\"\n",
    "    \n",
    "    display(HTML(centered_html))\n",
    "\n",
    "\n",
    "# display dataframes horizontally with title for each\n",
    "def display_h(frames, space=100):\n",
    "    html = \"\"\n",
    "    \n",
    "    for key in frames.keys():\n",
    "        html_df =f'<div>{key} {frames[key]._repr_html_()}</div>'\n",
    "        html += html_df\n",
    "        \n",
    "    html = f\"\"\"\n",
    "    <div style=\"display:flex; justify-content: space-evenly;\">\n",
    "    {html}\n",
    "    </div>\"\"\"\n",
    "    \n",
    "    display_html(html, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e1fbca75-268c-497f-99c3-a81292f2cbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applies cell color to a given nth percentile\n",
    "def style_percentile(i, percentile='50th'):\n",
    "    return ['background-color: Aquamarine' if i.name == percentile else '' for _ in i]\n",
    "\n",
    "# return quatiles for a given series (dataframe and column name)\n",
    "def quantiles(frame, col='risk', style_median=False, return_counts=True):\n",
    "    \n",
    "    quantile_values = [0.1, 0.25, 0.5, 0.7, 0.9, 0.99]\n",
    "    qdict = {f\"{int(q * 100)}th\": frame[col].quantile(q) for q in quantile_values}\n",
    "    \n",
    "    df = pd.DataFrame(list(qdict.items()), columns=['percentile', col])    \n",
    "    \n",
    "    if return_counts:\n",
    "        df['count'] = df[col].apply(lambda x: round(frame[frame[col] >= x].shape[0] / 30, 0))\n",
    "    \n",
    "    df[col] = round(df[col], 3)\n",
    "    df['count'] = df['count'].astype(int)\n",
    "    df.set_index('percentile', inplace=True)\n",
    "    \n",
    "    if style_median:\n",
    "        df = df.style.apply(style_percentile, axis=1).format(\"{:.1f}\")\n",
    "        return df\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b2dfc2d-03e7-4c97-a2f6-7f00ff616c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- rev_id: long (nullable = true)\n",
      " |-- wiki_db: string (nullable = true)\n",
      " |-- rev_timestamp: string (nullable = true)\n",
      " |-- revision_is_identity_reverted: boolean (nullable = true)\n",
      " |-- revision_seconds_to_identity_revert: long (nullable = true)\n",
      " |-- page_id: long (nullable = true)\n",
      " |-- revision_revert_risk: float (nullable = true)\n",
      " |-- user_is_anonymous: boolean (nullable = true)\n",
      " |-- user_is_bot: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# paths to pre-calculated revert risk scores\n",
    "# generated by https://gitlab.wikimedia.org/repos/research/knowledge_integrity/-/blob/mnz/examples/examples/notebooks/revertrisk_example.ipynb\n",
    "rr_scores_path = '/user/paragon/riskobservatory/revertrisk_20212022_anonymous_bot.parquet'\n",
    "\n",
    "rr_scores = spark_session.read.parquet(rr_scores_path)\n",
    "rr_scores.createOrReplaceTempView('rr_scores')\n",
    "\n",
    "rr_scores.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1af5eb8-6f3f-4f25-9d83-5c7f2110c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_comp = pd.read_csv('https://raw.githubusercontent.com/wikimedia-research/wiki-comparison/main/data-collection/snapshots/Jan_2023.tsv', sep='\\t')\n",
    "top15_wps = wiki_comp[wiki_comp['project code'] == 'wikipedia'][:15]['database code'].values.tolist()\n",
    "top15_wps_sql = wmf.utils.sql_tuple(top15_wps)\n",
    "mwh_snapshot = '2023-12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79e46b41-87f8-49aa-9a2a-84d8b93cd777",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve '`revision_id`' given input columns: []; line 61 pos 19;\n'Project ['COUNT(distinct 'revision_id) AS total_edits#0, 'COUNT(distinct CASE WHEN 'page_namespace_is_content THEN 'revision_id ELSE null END) AS mainspace_edits#1, 'COUNT(distinct CASE WHEN ('page_namespace_is_content AND ('revision_parent_id = 0)) THEN 'revision_id ELSE null END) AS page_creations#2, 'COUNT(distinct CASE WHEN (('page_namespace_is_content AND ('revision_parent_id = 0)) AND 'page_is_redirect) THEN 'revision_id ELSE null END) AS page_creations_redirects#3, 'COUNT(distinct CASE WHEN (('page_namespace_is_content AND ('revision_parent_id = 0)) AND NOT 'page_is_redirect) THEN 'revision_id ELSE null END) AS page_creations_non_redirects#4, 'COUNT(distinct CASE WHEN ('page_namespace_is_content AND 'is_bot) THEN 'revision_id ELSE null END) AS mainspace_bot_edits#5, 'COUNT(distinct CASE WHEN ('page_namespace_is_content AND 'is_sysop) THEN 'revision_id ELSE null END) AS mainspace_sysop_edits#6, 'COUNT(distinct CASE WHEN ('page_namespace_is_content AND 'is_revert) THEN 'revision_id ELSE null END) AS mainspace_reverts#7, 'COUNT(distinct CASE WHEN ('page_namespace_is_content AND 'is_self_revert) THEN 'revision_id ELSE null END) AS mainspace_self_reverts#8, 'FROM AS edits#9]\n+- OneRowRelation\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 74\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mWITH\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124m    base AS (\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124m    edits\u001b[39m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 74\u001b[0m reviews_info \u001b[38;5;241m=\u001b[39m \u001b[43mwmf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/2023-03-31T07.02.22_kcv-wikimf/lib/python3.10/site-packages/wmfdata/spark.py:282\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(commands)\u001b[0m\n\u001b[1;32m    279\u001b[0m overall_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cmd \u001b[38;5;129;01min\u001b[39;00m commands:\n\u001b[0;32m--> 282\u001b[0m     cmd_result \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# If the result has columns, the command was a query and therefore\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;66;03m# results-producing. If not, it was a DDL or DML command and not\u001b[39;00m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# results-producing.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cmd_result\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/2023-03-31T07.02.22_kcv-wikimf/lib/python3.10/site-packages/pyspark/sql/session.py:723\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msql\u001b[39m(\u001b[38;5;28mself\u001b[39m, sqlQuery):\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;124;03m\"\"\"Returns a :class:`DataFrame` representing the result of the given query.\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \n\u001b[1;32m    710\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 2.0.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;124;03m    [Row(f1=1, f2='row1'), Row(f1=2, f2='row2'), Row(f1=3, f2='row3')]\u001b[39;00m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped)\n",
      "File \u001b[0;32m/usr/lib/spark3/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/.conda/envs/2023-03-31T07.02.22_kcv-wikimf/lib/python3.10/site-packages/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve '`revision_id`' given input columns: []; line 61 pos 19;\n'Project ['COUNT(distinct 'revision_id) AS total_edits#0, 'COUNT(distinct CASE WHEN 'page_namespace_is_content THEN 'revision_id ELSE null END) AS mainspace_edits#1, 'COUNT(distinct CASE WHEN ('page_namespace_is_content AND ('revision_parent_id = 0)) THEN 'revision_id ELSE null END) AS page_creations#2, 'COUNT(distinct CASE WHEN (('page_namespace_is_content AND ('revision_parent_id = 0)) AND 'page_is_redirect) THEN 'revision_id ELSE null END) AS page_creations_redirects#3, 'COUNT(distinct CASE WHEN (('page_namespace_is_content AND ('revision_parent_id = 0)) AND NOT 'page_is_redirect) THEN 'revision_id ELSE null END) AS page_creations_non_redirects#4, 'COUNT(distinct CASE WHEN ('page_namespace_is_content AND 'is_bot) THEN 'revision_id ELSE null END) AS mainspace_bot_edits#5, 'COUNT(distinct CASE WHEN ('page_namespace_is_content AND 'is_sysop) THEN 'revision_id ELSE null END) AS mainspace_sysop_edits#6, 'COUNT(distinct CASE WHEN ('page_namespace_is_content AND 'is_revert) THEN 'revision_id ELSE null END) AS mainspace_reverts#7, 'COUNT(distinct CASE WHEN ('page_namespace_is_content AND 'is_self_revert) THEN 'revision_id ELSE null END) AS mainspace_self_reverts#8, 'FROM AS edits#9]\n+- OneRowRelation\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "WITH\n",
    "    base AS (\n",
    "        SELECT\n",
    "            wiki_db,\n",
    "            revision_id,\n",
    "            page_namespace_is_content,\n",
    "            revision_parent_id,\n",
    "            page_is_redirect,\n",
    "            CASE\n",
    "                WHEN SIZE(event_user_is_bot_by_historical) > 0 THEN TRUE\n",
    "                ELSE FALSE\n",
    "            END AS is_bot,\n",
    "            CASE \n",
    "                WHEN ARRAY_CONTAINS(mwh.event_user_groups_historical, 'sysop') THEN TRUE\n",
    "                ELSE FALSE\n",
    "            END AS is_sysop,\n",
    "            revision_is_identity_revert AS is_revert\n",
    "        FROM\n",
    "            wmf.mediawiki_history\n",
    "        WHERE\n",
    "            snapshot = '{mwh_snapshot}'\n",
    "            AND wiki_db IN {top15_wps_sql}\n",
    "            AND YEAR(event_timestamp) = 2022\n",
    "    ),\n",
    "    \n",
    "    self_reverts AS (\n",
    "        SELECT\n",
    "            b.*,\n",
    "            CASE\n",
    "                WHEN b.event_user_text = mwh.event_user_text THEN TRUE\n",
    "                ELSE FALSE\n",
    "            END is_self_revert\n",
    "        FROM\n",
    "            base b\n",
    "        JOIN\n",
    "            wmf.mediawiki_history mwh\n",
    "            ON mwh.revision_first_identity_reverting_revision_id = b.revision_id\n",
    "                AND mwh.wiki_db = b.wiki_db\n",
    "        WHERE\n",
    "            snapshot = '{mwh_snapshot}'\n",
    "            AND is_revert    \n",
    "    ),\n",
    "    \n",
    "    edits AS (\n",
    "        SELECT\n",
    "            *,\n",
    "            NULL AS is_self_revert\n",
    "        FROM\n",
    "            base\n",
    "        WHERE\n",
    "            NOT is_revert\n",
    "        UNION ALL\n",
    "        SELECT\n",
    "            *\n",
    "        FROM \n",
    "            self_reverts\n",
    "    )\n",
    "\n",
    "SELECT\n",
    "    COUNT(DISTINCT revision_id) AS total_edits,\n",
    "    COUNT(DISTINCT CASE WHEN page_namespace_is_content THEN revision_id ELSE NULL END) AS mainspace_edits,\n",
    "    COUNT(DISTINCT CASE WHEN page_namespace_is_content AND revision_parent_id = 0 THEN revision_id ELSE NULL END) AS page_creations,\n",
    "    COUNT(DISTINCT CASE WHEN page_namespace_is_content AND revision_parent_id = 0 AND page_is_redirect THEN revision_id ELSE NULL END) AS page_creations_redirects,\n",
    "    COUNT(DISTINCT CASE WHEN page_namespace_is_content AND revision_parent_id = 0 AND NOT page_is_redirect THEN revision_id ELSE NULL END) AS page_creations_non_redirects,\n",
    "    COUNT(DISTINCT CASE WHEN page_namespace_is_content AND is_bot THEN revision_id ELSE NULL END) AS mainspace_bot_edits,\n",
    "    COUNT(DISTINCT CASE WHEN page_namespace_is_content AND is_sysop THEN revision_id ELSE NULL END) AS mainspace_sysop_edits,\n",
    "    COUNT(DISTINCT CASE WHEN page_namespace_is_content AND is_revert THEN revision_id ELSE NULL END) AS mainspace_reverts,\n",
    "    COUNT(DISTINCT CASE WHEN page_namespace_is_content AND is_self_revert THEN revision_id ELSE NULL END) AS mainspace_self_reverts,\n",
    "FROM\n",
    "    edits\n",
    "\"\"\"\n",
    "\n",
    "reviews_info = wmf.spark.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5aa2b0-01df-4edf-a50a-f52e1ed38dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "          "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
